{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code imports\n",
    "from lib.opt_types import *\n",
    "from lib.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Order Methods - 25 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a means of estimating the unknown parameter $\\mathbf{x}^\\natural$, your labor in part 1 led you to define the following optimization problem:\n",
    "\\begin{equation}\n",
    "\t\\mathbf{x}^\\star=\\arg\\min_{\\mathbf{x} \\in \\mathbb{R}^p} f_\\mu(\\mathbf{x}) \\equiv  f(\\mathbf{x}) + \\frac{\\mu}{2}\\|\\mathbf{x}\\|_2^2.\n",
    "\\tag{1}\n",
    "\\end{equation}\n",
    "\n",
    "The optimality condition of (1) is\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla f_\\mu({\\mathbf x}^\\star) = \\sum_{i=1}^n -b_i \\sigma(-b_i \\cdot \\mathbf{a}_i^T\\mathbf{x}^\\star)\\mathbf{a}_i + \\mu \\mathbf{x}^\\star = 0. \\tag{2}\n",
    "\\end{equation}\n",
    "\n",
    "Thanks to convexity, condition (2) is in fact the necessary and sufficient condition for $\\mathbf x^\\star$ to be optimal.\n",
    "We can equivalently write this condition as\n",
    "\\begin{equation}\n",
    "\\mathbf x^\\star = {\\mathbf x}^\\star - \\mathbf{B} \\nabla f_\\mu({\\mathbf x}^\\star) \\tag{3}\n",
    "\\end{equation}\n",
    "for any symmetric, positive definite matrix $\\mathbf{B}$. \n",
    "This is a fixed-point formulation of (1), which will be used to develop first-order methods.\n",
    "\n",
    "\n",
    "Notice that choosing $\\mathbf{B} = \\alpha \\mathbb{I}$ with $\\alpha > 0$ in the formulation (3) suggests that the gradient descent method can be used to solve (1). \n",
    "\n",
    "In this part, you will implement different variants of the gradient descent algorithm. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code structure:\n",
    "\n",
    "A `Function` is a type that has the following attributes:\n",
    "\n",
    "```python\n",
    "@dataclass\n",
    "class Function:\n",
    "    f              # The function that is being minimized\n",
    "    grad           # The gradient of the function\n",
    "    f_star         # The minimum of the function\n",
    "    strng_cvx      # The strong convexity constant, if it admits one\n",
    "    lips_grad      # The smoothness constant, if it admits one\n",
    "```\n",
    "\n",
    "For a given function `f = Function()`:\n",
    "- You can evaluate the function at a point `x` by simply writing `f(x)`.\n",
    "- You can evaluate the gradient at a point `x` by writing `f.grad(x)`.\n",
    "- You can get the smoothness constant by writing `f.lips_grad`.\n",
    "- You can get the strong convexity constant by writing `f.strng_cvx`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have defined the function that we are trying to minimize $f_\\mu$ and stored in the object `f`, and we have provided you with an inital guess of a solution `x_zero`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.part_one import f, x_zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for you to test your algorithms, we have also provided you with a `test` function that runs a given method on a strongly convex quadratic function $x \\mapsto \\frac{1}{2}x^\\top M x$ for `100` iterations that we intialize at $x_0 = \\begin{bmatrix} 100.0& 100.0 \\end{bmatrix}$. For example, once you implement `GD` you can test it by running\n",
    "\n",
    "```python\n",
    "test(GD)\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Run the cells !</b> Make sure you run all the code cells as some variables are defined and used in mutiple subsequent cells.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variants of Gradient Descent\n",
    "\n",
    "Now you will implement various methods to iteratively improve the initial guess `x_zero`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(a)__ (2.5 points) The main ingredients of the gradient descent algorithm are the descent direction (the negative gradient) and the step-size $\\alpha_k$. \n",
    "In this part, we consider the gradient descent algorithm with constant step-size ${1}/{L}$, i.e., $\\alpha_k = {1}/{L}$ for any $k = 0,1,...$ where $L$ is the gradient-Lipschitz constant of the function `f`. \n",
    "\n",
    "Gradient Descent, as an iterative scheme, only tracks the current iterate `x_k` and the step size `alpha_k`. We store them both in a state variable that holds both these attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GD_state(OptState):\n",
    "    x_k: Vector\n",
    "    alpha_k: float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a function `f` and a state at some iteration $k$, recall how GD updates the state and fill in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GD_update(f, state):\n",
    "    x_k, alpha_k = state\n",
    "    \n",
    "    x_next = #FILL\n",
    "    \n",
    "    return GD_state(x_k = x_next, alpha_k = alpha_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having defined the `GD_update` which updates a given state, we now need to initialize the state. Fill in the cell below, recalling that you are given an initial guess `x_zero`, and the fact that we are using a fixed step size corresponding to the smoothness constant of `f`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GD_initialize(f, x_zero):\n",
    "    x_k = #FILL\n",
    "    alpha_k = #FILL\n",
    "    return GD_state(x_k, alpha_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the initialization and the update scheme specified, we define the algorithm in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GD = OptAlgorithm(name=\"GD\", init_state = GD_initialize, state_update = GD_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(GD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now notice that the objective function is strongly convex. Therefore, we can select the constant step-size $\\alpha$ as $2/(L+\\mu)$ to get a faster convergence rate. We call this algorithm `GDstr`.\n",
    "\n",
    "Both `GD` and `GDstr` have the same state update but only differ in the stepsize they use. Implement this variant of the gradient descent method by completing the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GDstr_initialize(f, x_zero):\n",
    "    x_k = #FILL\n",
    "    alpha_k = #FILL\n",
    "    return GD_state(x_k, alpha_k)\n",
    "    \n",
    "GDstr = OptAlgorithm(name=\"GDstr\", init_state = GDstr_initialize, state_update = GD_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(GDstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(b-1)__ (1.5 points) We can accelerate the above gradient descent algorithm with the following scheme ($t_0=1$):\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{array}{ll}\n",
    "\\mathbf{x}^{k+1} &:=  \\mathbf{y}^k - \\alpha_k\\nabla{f_\\mu}(\\mathbf{y}^k),\\\\\n",
    "t_{k+1} &:= \\frac{1}{2}(1 + \\sqrt{1 + 4t_k^2})\\\\\n",
    "\\mathbf{y}^{k+1} &:= \\mathbf{x}^{k+1} + \\frac{t_k-1}{t_{k+1}}\\big(\\mathbf{x}^{k+1} - \\mathbf{x}^k\\big).\n",
    "\\end{array}\n",
    "\\end{equation*}\n",
    "\n",
    "Implement this algorithm with constant step-size $\\alpha = 1/L$, by completing the missing parts of the following cells.\n",
    "\n",
    "First we define the state that the algorithm updates at each iteration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AGD_state(OptState):\n",
    "    x_k: Vector\n",
    "    y_k: Vector\n",
    "    t_k: float\n",
    "    alpha_k: float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this `state` and a function `f` to optimize, write the update step of accelerated gradient descent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGD_update(f, state):\n",
    "    x_k, y_k, t_k, alpha_k = state\n",
    "    \n",
    "    next_x_k = #FILL\n",
    "    next_t_k = #FILL\n",
    "    next_y_k = #FILL\n",
    "    next_alpha_k = #FILL\n",
    "    \n",
    "    return AGD_state(x_k = next_x_k, y_k = next_y_k, t_k=next_t_k, alpha_k =next_alpha_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the initial state of AGD in the cell below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGD_initialize(f, x_zero):\n",
    "    return AGD_state(x_k = x_zero, y_k = x_zero, t_k=1, alpha_k =1.0/f.lips_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all the necessary ingredients to define the optimization algorithm in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGD = OptAlgorithm(name=\"AGD\", init_state=AGD_initialize, state_update=AGD_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(AGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(b-2)__ (1 points)\n",
    "\n",
    "Note that the objective function is strongly convex. Therefore, we can use the accelerated gradient algorithm for strongly convex objectives to converge faster. This variant can be summarized as follows:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\left\\{\\begin{array}{ll}\n",
    "\\mathbf{x}^{k+1} &:=  \\mathbf{y}^k - \\alpha_k\\nabla{f_\\mu}(\\mathbf{y}^k),\\\\\n",
    "\\mathbf{y}^{k+1} &:= \\mathbf{x}^{k+1} + m\\big(\\mathbf{x}^{k+1} - \\mathbf{x}^k\\big).\n",
    "\\end{array}\\right. \n",
    "\\end{equation*}\n",
    " \n",
    "Implement this variant of the accelerated gradient method by completing the following cells. Try different values of $m$ and comment on what should be the best value for this constant. Do the practical results follow the theory?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AGDstr_state(OptState):\n",
    "    x_k: Vector\n",
    "    y_k: Vector\n",
    "    alpha_k: float\n",
    "    m_strongcvx: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGDstr_update(f, state):\n",
    "    x_k, y_k, alpha_k, m_strongcvx = state\n",
    "    \n",
    "    #FILL\n",
    "    \n",
    "    return AGDstr_state(next_x_k, next_y_k, alpha_k, m_strongcvx)\n",
    "\n",
    "def AGDstr_initialize(f, x_zero):\n",
    "    m_strongcvx = ... # Pick value of m here\n",
    "    #FILL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGDstr = OptAlgorithm(name=\"AGDstr\", init_state=AGDstr_initialize, state_update=AGDstr_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(AGDstr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(c)__ (5 points) We can obtain better performance by considering a line search procedure, which adapts the step-size $\\alpha_k$ to the local geometry. \n",
    "The line-search strategy to determine the step-size $\\alpha_k$ for the standard GD algorithm,\n",
    "$\\mathbf{x}^{k+1}=\\mathbf{x}^k-\\alpha_k\\nabla f_\\mu(\\mathbf{x}^k),$\n",
    "is the following: \n",
    "\n",
    "At the step $kth$ iteration, let $\\mathbf{x}^k$ be the current iterate and $\\mathbf{d}^k=-\\nabla f_\\mu(\\mathbf{x}^k)$ be a given descent direction, and perform:\n",
    "* Set $L_0 = L$.\n",
    "* At each iteration, set $L_{k,0} = \\frac{1}{2}L_{k-1}$, where $k$ is the iteration counter. \n",
    "* Using a for loop, find the minimum integer $i \\geq 0$ that satisfies $f_\\mu\\left(\\mathbf{x}^k + \\frac{1}{2^i L_{k,0}} \\mathbf{d}^k\\right) \\leq f_\\mu(\\mathbf{x}^k) -\\frac{1}{2^{i+1} L_{k,0}} \\|\\mathbf{d}^k\\|^2$.\n",
    "* Set $L_k = {2^i L_{k,0}}$ and use the step-size $\\alpha_k := \\frac{1}{L_k}$ (i.e., use the new estimate that you have used in the line-search: $\\mathbf{x}^k + \\frac{1}{2^i L_{k,0}} \\mathbf{d}^k$).\n",
    "\n",
    "Complete the missing parts in order to implement gradient descent with line-search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class LS_GD_state(OptState):\n",
    "    #FILL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LS_GD_update(f, state):\n",
    "    \n",
    "    #FILL\n",
    "    \n",
    "    return #FILL\n",
    "    \n",
    "def LS_GD_initialize(f, x_zero):\n",
    "    return #FILL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LS_GD = OptAlgorithm(name=\"LS_GD\", init_state = LS_GD_initialize, state_update=LS_GD_update )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(LS_GD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now incorporate a line-search enhancement to the accelerated gradient method implemented in (b). At step $k$, \n",
    "we have the current iteration $\\mathbf{x}^k$ together with an _intermediate variable_ $\\mathbf{y}^k$ and its corresponding direction $\\mathbf{d}^k=-\\nabla f_\\mu(\\mathbf{y}^k)$. **Note that the intermediate variable is then used in the gradient step and hence the line-search will be performed on it to determine the step-size**.\n",
    "\n",
    "\n",
    "Perform a line-search strategy with respect to $\\mathbf{y}^k$ and direction $\\mathbf{d}^k$ to determine the step-size $\\alpha_k$ as follows:\n",
    "\n",
    "* Set $L_0 = L$.\n",
    "* At each iteration, set $L_{k,0} = \\frac{1}{2}L_{k-1}$, where $k$ is the iteration counter. \n",
    "* Using a for loop, find the minimum integer $i \\geq 0$ that satisfies $f_\\mu\\left(\\mathbf{y}^k + \\frac{1}{2^i L_{k,0}} \\mathbf{d}^k\\right) \\leq f_\\mu(\\mathbf{y}^k) -\\frac{1}{2^{i+1} L_{k,0}} \\|\\mathbf{d}^k\\|^2$.\n",
    "* Set $L_k = {2^i L_{k,0}}$ and use the step-size $\\alpha_k := \\frac{1}{L_k}$.\n",
    " \n",
    "Update the next iterations:\n",
    "\\begin{equation*}\n",
    "\\left\\{\\begin{array}{ll}\n",
    "\\mathbf{x}^{k+1} &:=  \\mathbf{y}^k - \\alpha_k\\nabla{f_\\mu}(\\mathbf{y}^k),\\\\\n",
    "t_{k+1} &:= \\frac{1}{2}\\left(1 + \\sqrt{1 + 4\\frac{L_k}{L_{k-1}}t_k^2}\\right)\\\\\n",
    "\\mathbf{y}^{k+1} &:= \\mathbf{x}^{k+1} + \\frac{t_k-1}{t_{k+1}}\\big(\\mathbf{x}^{k+1} - \\mathbf{x}^k\\big).\n",
    "\\end{array}\\right.\n",
    "\\end{equation*}\n",
    "\n",
    "Complete the missing parts in order to implement accelerated gradient descent with line-search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class LS_AGD_state(OptState):\n",
    "    #FILL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LS_AGD_update(f, state):\n",
    "    #FILL\n",
    "    \n",
    "    return #FILL\n",
    "\n",
    "def LS_AGD_initialize(f, x_zero):\n",
    "    return #FILL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LS_AGD = OptAlgorithm(name=\"LS_AGD\", init_state=LS_AGD_initialize, state_update=LS_AGD_update )#FILL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(LS_AGD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(d)__ (5 points) The accelerated gradient method is non-monotonic, so it can be oscillatory, i.e. $f_\\mu(\\mathbf{x}^{k+1})\\not\\leq f_\\mu(\\mathbf{x}^k)$ for all $k\\geq 0$.\n",
    "To prevent such behavior, we can use the so-called adaptive restart strategy. \n",
    "In short, this strategy can be explained as follows: \n",
    "At each iteration, whenever $\\mathbf{x}^{k+1}$ is computed, we evaluate $f_\\mu(\\mathbf{x}^{k+1})$ and compare it with $f_\\mu(\\mathbf{x}^k)$: \n",
    "\n",
    "* If $f_\\mu(\\mathbf{x}^k) < f_\\mu(\\mathbf{x}^{k+1})$, restart the iteration, i.e., recompute $\\mathbf{x}^{k+1}$ by setting $\\mathbf{y}^{k} := \\mathbf{x}^{k}$ and $t_{k} := 1$;\n",
    "* Otherwise, let the algorithm continue.\n",
    "\n",
    "\n",
    "This strategy requires the evaluation of the function value at each iteration, which increases the computational complexity of the overall algorithm. \n",
    "\n",
    "Implement the adaptive restart strategy which uses the function values for the accelerated gradient algorithm with constant step-size $\\alpha_k=1/L$ \n",
    "by completing the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AGDR_state(AGD_state):\n",
    "    #FILL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AGDR_update(f, state):\n",
    "    #FILL\n",
    "    \n",
    "    return #FILL\n",
    "\n",
    "AGDR_initialize = AGD_initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AGDR = OptAlgorithm(name=\"AGDR\", init_state = AGDR_initialize, state_update=AGDR_update)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(AGDR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(e)__ (Self-study, 0 points)\n",
    "Incorporate the line-search, acceleration and function values restart by completing the function LSAGDR. \n",
    "\n",
    "**Hint:** Note that while the restart is executed on $\\mathbf{x}^k$, the line-search strategy is executed on $\\mathbf{y}^k$ and the direction $\\mathbf{d}^k=-\\nabla f(\\mathbf{y}^k)$ to determine the \n",
    "step-size and hence, use line-search each time you encounter an intermediate variable $\\mathbf{y}^k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass \n",
    "class LS_AGDR_state(LS_AGD_state):\n",
    "    #FILL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LS_AGDR_update(f, state):\n",
    "    #FILL\n",
    "    \n",
    "    return #FILL\n",
    "\n",
    "def LS_AGDR_initialize(f, x_zero):\n",
    "    return #FILL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LS_AGDR = OptAlgorithm(name=\"LS_AGDR\", init_state=LS_AGDR_initialize, state_update=LS_AGDR_update)\n",
    "\n",
    "test(LS_AGDR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(f)__ (4 points) We can also apply an optimization technique that does not exploit the knowledge of the Lipschitz constant, and instead adapts to the local geometry by making use of past gradient information. AdaGrad adapts the step-size using the inverse square $\\ell_2$-norm of past gradients. Starting with $Q_0 = 0$ it iterates as follows:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\left\\{\\begin{array}{ll}\n",
    "Q_k &{\\!\\!\\!\\!}= Q_{k-1} + \\|\\nabla f_\\mu(\\mathbf{x}^k)\\|^2 \\\\\n",
    "\\mathbf{H}_k &{\\!\\!\\!\\!}= (\\sqrt{Q_k} + \\delta) I \\\\\n",
    "\\mathbf{x}^{k+1} &{\\!\\!\\!\\!}= \\mathbf{x}^k - \\alpha \\mathbf{H}_k^{-1} \\nabla f_\\mu(\\mathbf{x}^k)\n",
    "\\end{array}\\right.\n",
    "\\end{equation*}\n",
    "\n",
    "Complete the missing parts in the function AdaGrad in order to implement the above adaptive gradient method using $\\alpha = 1$, $\\delta = 10^{-5}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class AdaGrad_state(OptState):\n",
    "    #FILL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AdaGrad_update(f, state):\n",
    "    #FILL\n",
    "    \n",
    "    return #FILL\n",
    "\n",
    "def AdaGrad_initialize(f, x_zero):\n",
    "    return #FILL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaGrad = OptAlgorithm(name=\"AdaGrad\", init_state=AdaGrad_initialize, state_update=AdaGrad_update)\n",
    "test(AdaGrad, maxiter=30000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__(g)__ (2.5 points) Another famous adaptive optimization method is called the ADAptive Moment estimation algorithm, also known as ADAM, \n",
    "\n",
    "\\begin{equation*}\n",
    "\\left\\{\\begin{array}{ll}\n",
    "\\mathbf{g}_k &{\\!\\!\\!\\!} = \\nabla f_\\mu(\\mathbf{x}^{k}) \\\\\n",
    "\\mathbf{m}_{k+1} &{\\!\\!\\!\\!} = \\beta_1 \\mathbf{m}_{k} + (1-\\beta_1)\\mathbf{g}_k \\ \\textrm{$\\leftarrow$ Momentum}\\\\\n",
    "\\mathbf{v}_{k+1} &{\\!\\!\\!\\!} = \\beta_2 \\mathbf{v}_{k} + (1-\\beta_2)\\mathbf{g}_k^2 \\ \\textrm{$\\leftarrow$ Adaptive term}\\\\\n",
    "\\hat{\\mathbf{m}}_{k+1} &{\\!\\!\\!\\!} = \\mathbf{m}_{k+1} / (1-\\beta_1^{k+1})\\\\\n",
    "\\hat{\\mathbf{v}}_{k+1} &{\\!\\!\\!\\!} = \\mathbf{v}_{k+1} / (1-\\beta_2^{k+1}) \\ \\textrm{$\\leftarrow$ Scaling for removing bias}\\\\\n",
    "\\mathbf{H}_{k+1} &{\\!\\!\\!\\!} \\ = \\sqrt{\\hat{\\mathbf{v}}_{k+1}} + \\epsilon \\\\\n",
    "\\mathbf{x}^{k+1} &{\\!\\!\\!\\!} = \\mathbf{x}^k - \\alpha \\hat{\\mathbf{m}}_{k+1} / \\mathbf{H}_{k+1}\n",
    "\\end{array}\\right.\n",
    "\\end{equation*}\n",
    "\n",
    "Note that all operations shown above, when applied to vectors, are applied element-wise. In particular, $\\mathbf{g}_k^2$ is a vector of the same size as $\\mathbf{g}_k$ where each element is squared.\n",
    "\n",
    "Complete the missing parts in the cells below in order to implement the above adaptive gradient method using $\\alpha = 0.1$, $\\beta_1 = 0.9$, $\\beta_2 = 0.999$ and $\\epsilon = 10^{-8}$.\n",
    "\n",
    "It has been shown that ADAM can fail to converge to the global minimum of a convex problem. The authors provided a variant of ADAM, called AMSgrad in order to fix this convergence issue. However, in practice it is not clear which method performs best. (You are not required to implement this method, but advised to have a look at it for personal interest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ADAM_state(OptState):\n",
    "    #FILL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ADAM_update(f, state):\n",
    "    #FILL\n",
    "    \n",
    "    return #FILL\n",
    "\n",
    "def ADAM_initialize(f, x_zero):\n",
    "    return #FILL\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ADAM = OptAlgorithm(name=\"ADAM\", init_state=ADAM_initialize, state_update=ADAM_update)\n",
    "\n",
    "test(ADAM, maxiter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scheduler Free Optimizer\n",
    "\n",
    "Schedule-Free learning replaces the momentum of an underlying optimizer with a combination of interpolation and averaging. In the case of gradient descent, the basic Schedule-Free update is:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "y_{t} & = (1-\\beta)z_{t} + \\beta x_{t},\\\\\n",
    "z_{t+1} & =z_{t}-\\gamma\\nabla f(y_{t}),\\\\\n",
    "x_{t+1} & =\\left(1-\\frac{1}{t+1}\\right)x_{t}+\\frac{1}{t+1}z_{t+1},\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Here $x$ is the sequence that evaluations of test/val loss should occur at, which differs from the primary iterates $z$ and the gradient evaluation locations $y$. The updates to $z$ correspond to the underlying optimizer, in this case a simple gradient step.\n",
    "\n",
    "As the name suggests, Schedule-Free learning does not require a decreasing learning rate schedule, yet typically out-performs, or at worst matches, SOTA schedules such as cosine-decay and linear decay. Only two sequences need to be stored at a time (the third can be computed from the other two on the fly) so this method has the same memory requirements as the base optimizer (parameter buffer + momentum).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Scheduler_free_state(OptState):\n",
    "    #FILL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)** (0.5 points) Fill the initializer for the scheduler free optimizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Scheduler_free_update(f, state):\n",
    "    #FILL\n",
    "    \n",
    "    return #FILL\n",
    "\n",
    "def Scheduler_free_initialize(f, x_zero):\n",
    "    return #FILL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** (1 points) Build the scheduler free optimizer main update state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SFO = OptAlgorithm(name=\"Scheduler_Free_Optimizer\", init_state=Scheduler_free_initialize, state_update=Scheduler_free_update)\n",
    "\n",
    "test(SFO, maxiter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** (1 points) Run your experiment and discuss why the algorithm is referred to as a scheduler-free optimizer. For reference, it is beneficial to review [Road Less Scheduled](https://arxiv.org/abs/2405.15682)\n",
    " to gain a deeper understanding of the concepts and rationale behind this terminology.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the methods - 1 Point\n",
    "\n",
    "\n",
    "With these iterative shemes implemented, we will try to solve one logistic regression problem.\n",
    "\n",
    "We are going to model the probablity that a basketball shot succesfully enters the net using the logistic model introduced in the first part of the homework.\n",
    "\n",
    "Our data originates from motion tracking data captured by the NBA during the 2015-2016 season.\n",
    "\n",
    "<img width=50% src='lib/golden_state_shots.png'/>\n",
    "\n",
    "We consider the `3376` shots made by the Golden State Warriors. The labels ${b}_i$ will correspond to whether or not the shot $i$ was succesful, and $\\mathbf{a}_i$ will be a feature vector of dimension 5 containing the x-location, the y-location (of the player shooting on the basketball court), the distance to the basket, the number of minutes and the number of seconds left before the end of the quarter.\n",
    "\n",
    "The following cell runs the methods you have implemented on the logistic loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.part_one import f, x_zero, train_accuracy\n",
    "\n",
    "#Remove methods you have not implemented\n",
    "methods = [GD, GDstr, AGD, AGDstr, LS_GD, AGDR, AdaGrad, ADAM, SFO]\n",
    "\n",
    "plot(methods, f, x_zero, max_iteration=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, think you are an NBA team general manager and you have access to the data described above for the 2015-2016 season. You want to pick a good performing method to predict the scoring efficiency of opposite teams - in order to adjust your team accordingly. Run the fillowing cell to display the training accuracy of your solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = #FILL\n",
    "run_trace = run(method, f, x_zero, 5000)\n",
    "last_x_k = run_trace.sequence[-1]\n",
    "\n",
    "train_accuracy(run_trace.sequence[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given we have access to as many as `84467` distinct shots from all teams that played in 2015-2016, what could we do to improve our method? What consequences could that bring when running our deterministic methods? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "custom_cell_magics": "kql"
  },
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
